---
title: |
  | **Submitted to Meta-Psychology. Click here to follow the fully transparent editorial process of this submission. Participate in open peer review by commenting through hypothes.is directly on this preprint.**
  | 
  | 
  | Re-analysing the data from @moffatt_inner_2020: A textbook illustration of the absence of evidence fallacy

shorttitle: "The absence of evidence fallacy"

author: 
  - name: Ladislas Nalborczyk
    affiliation: 1
    corresponding: yes
    address: GIPSA-lab, CNRS, Univ. Grenoble Alpes, 11 Rue des Mathématiques, 38400 Saint-Martin-d'Hères, France
    email: ladislas.nalborczyk@gipsa-lab.fr

affiliation:
  - id: 1
    institution: Univ. Grenoble Alpes, CNRS, Grenoble INP, GIPSA-lab, 38000 Grenoble, France

abstract: "@moffatt_inner_2020 reported the results of an experiment (N = 26 in the final sample) comparing the facial (surface) electromyographic correlates of mental rumination and distraction, following an experimentally induced stressor. Based on the absence of significant difference in the perioral muscular activity between the rumination and distraction conditions, @moffatt_inner_2020 concluded that *self-reported* inner experience was unrelated to peripheral muscular activity as assessed using surface electromyography. We suggest this conclusion is hasty and based on waggly evidence. Indeed, concluding on the absence of an effect based on a low-powered non-significant p-value is strongly problematic/uninformative. Moreover, the relation between self-reports and physiological measures was not *directly* assessed, but only indirectly inferred from differences (or absence thereof) in group means. Given the ample inter-individual variability in these measures (as suggested by our reanalysis), we think inferring the individual-level relation between self-reports and physiological measures from group means is inappropriate. Given these limitations, we conclude that it is unclear whether the target article adds to the current/extent knowledge and we suggest ways forward, both from a theoretical and from a methodological perspective. Complete source code, reproducible analyses, and figures are available at https://github.com/lnalborczyk/inner_experience_EMG."

keywords: NHST, Bayesian, fallacy, reanalysis, inner speech, rumination, electromyography
csl: csl/apa7.csl
classoption: man, donotrepeattitle
linenumbers: yes
floatsintext: yes
link-citations: true
numbersections: false

bibliography: [bib/library.bib, bib/r-references.bib]

nocite: | 
  @R-base, @R-knitr, @R-rmarkdown, @R-tidyverse, @R-papaja, @R-wordcountaddin,
  @R-here

output:
  papaja::apa6_pdf:
    keep_tex: true
    highlight: tango
    latex_engine: xelatex

editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE, message = FALSE, warning = FALSE}
library(wordcountaddin)
library(BayesFactor)
library(ggbeeswarm)
library(rmarkdown)
library(tidyverse)
library(patchwork)
library(parallel)
library(papaja)
library(readxl)
library(knitr)
library(BEST)
library(brms)
library(glue)
library(here)
library(pwr)

# setting seed for reproducibility
# set.seed(666)

# setting up knitr options
knitr::opts_chunk$set(
  cache = TRUE, eval = TRUE, echo = FALSE,
  warning = FALSE, message = FALSE,
  fig.align = "center", dev = "pdf",
  out.width = "100%", fig.width = 8,
  fig.pos = "!htb"
  )

# counting words in the current .Rmd file
wordcount <- word_count(knitr::current_input() )
```

<!--

NB: You can add comments using these tags

Wordcount (excluding abstract, references, tables, and figures): `r wordcount`

-->

\newpage

# Introduction

The activity of silently talking to oneself or "inner speech" is a foundational ability, allowing oneself to remember, plan, self-motivate or self-regulate [for reviews, see @alderson-day_inner_2015; @perrone-bertolotti_what_2014; @loevenbruck_cognitive_2018]. Although there are debates about the exact nature of inner speech and whether it is better described as the... of abstract linguistic representations or as the...

<!--

However, whereas the use inner speech is associated with plenty of adaptive functions in everyday life, inner speech dysfunctions are suspected to play a role in multiple psychological disorders...

-->

Given the predominantly verbal nature of rumination [e.g., @ehring_repetitive_2008; @goldwin_concreteness_2012; @goldwin_concreteness_2013; @mclaughlin_effects_2007], we previously proposed to consider rumination as a form of inner speech and to study it using the methods that have been used to study other forms of inner speech, namely, by using surface electromyography and motor interference protocols [e.g., @nalborczyk_orofacial_2017; @nalborczyk_understanding_2019; @nalborczyk_dissociating_2020; @nalborczyk_articulatory_2020]. We first showed that induced rumination was accompanied by increased facial (both over a forehead and a perioral site) muscular activity in comparison to a rest period [@nalborczyk_orofacial_2017]. However, because rumination was only compared to a rest period, it remained uncertain whether this perioral activity was specifically related to (inner) speech processes. Therefore, we ran an extension of this study, in which we compared verbal to non-verbal rumination, which suggested that the facial EMG correlates we have previously identified were not specifically related to the verbal content of the ruminative thoughts [@nalborczyk_dissociating_2020]. We discussed these findings in length and proposed several theoretical interpretations that can account for these results in the discussion section of @nalborczyk_dissociating_2020 and more extensively in @nalborczyk_understanding_2019. Although these discussions were blatantly ignored by @moffatt_inner_2020, their experimental design nevertheless had the potential to inform our understanding of the involvement of the speech motor system in different varieties of inner speech as well as to clarify the relation between the peripheral correlates of inner speech and the (self-reported) subjective experience.

The main conclusion from @moffatt_inner_2020 is that inner experience between induced rumination and distraction differs "without a change in electromyographic correlates of inner speech". In other words, they suggest that the subjective experience of inner speech is unrelated (or loosely related) to the electromyographic correlates of inner speech, which are thought to be represented mostly by the EMG amplitude recorded over the OOI and OOS muscles. However, for this in-sample observation to be of interest in an out-of-sample context (i.e., to be informative of other non-observed individuals, or said otherwise, to bring information about the population), this absence of difference has to be based on sufficiently powered sample size (given the target effect size) as well as on reliable measures. This is unlikely to be the case here, for reasons that we will present and discuss in the present article. Moreover, a simple visual exploration of the data reveals important variability between individuals in the main effect of interest. That is, some participants had higher perioral (OOS and OOI) muscular activity in the rumination condition than in the distraction condition, and some other participants showed the reverse pattern. This suggests unexplored variation in the determinants of this effect (e.g., the content of the inner experience). Indeed, the relation between the inner experience and the physiological correlates of inner speech production was only inferred from group means. However, given the important inter-individual variability, this reasoning appears highly problematic. In the following, we explore each of these limitations and suggests ways forward, both from a methodological and from a theoretical perspective.

# Exploring the data

As typical in studies manipulating induced rumination, @moffatt_inner_2020 designed a two-step protocol. First, they aimed to induce a negative mood by asking participants unsolvable and excessively difficult anagram and subtraction tasks, respectively. Second, they prompted the participants to either ruminate on these (purportedly induced) negative feelings (by asking them to "think about the causes, consequences, and meaning of their current feelings") or to distract themselves (by asking them to "think about a village, city or town that you are particularly familiar with"). Rumination and distraction was manipulated within-subject, will all subjects alternating between rumination and distraction, in a counter-balanced order.

```{r importing_data}
# importing data
df <- read_excel(path = "data/RUM_master_data.xlsx", sheet = 1)

# importing codebook
codebook <- read_excel(path = "data/RUM_master_data.xlsx", sheet = 2)

# data reshaping (from wide to long)
# NB: 26 participants in the final dataset...

# Order in which rumination and distraction inductions were completed
# 1 = rumination induction completed first
# 2 = distraction induction completed first

df2 <- df %>%
    select(ID, order = Order, RUM_FRO_MAX_ln:BAS_OOI_MAX_ln) %>%
    na.omit %>%
    # reshapes data from wide to long format
    pivot_longer(
        cols = starts_with(c("RUM", "DIS", "BAS") ),
        names_to = "condition",
        # names_prefix = "wk",
        values_to = "value",
        values_drop_na = TRUE
        ) %>%
    separate(
        col = condition,
        into = c("condition", "muscle"),
        sep = "_", extra = "merge"
        ) %>%
    # extracts muscle name
    mutate(muscle = substr(muscle, 1, 3) ) %>%
    # from long to wide
    pivot_wider(names_from = muscle, values_from = value)
```

Their final sample of participants, after data exclusion, included 26 participants (data available at https://osf.io/hj7tz/). The EMG data is depicted in Figure \@ref(fig:general) by condition (where `BAS`, `DIS`, and `RUM` refer to the baseline, distraction, and rumination conditions, respectively) and by muscle (`FRO`, `OOI`, `OOS`). This figure shows that the average natural logarithm of the EMG peak amplitude recorded over the FRO was at similar levels in the baseline and distraction conditions, but was much higher in the rumination condition. However, the average natural logarithm of the EMG peak amplitude recorded over the OOI and OOS muscles was higher than baseline in both the rumination and distraction conditions, with a slight increase from distraction to rumination (both on the mean and median).

```{r general, fig.cap = "Average natural logarithm of the EMG peak amplitude per muscle and condition. The black dots and intervals represent the by-group average and 95\\% confidence interval (N = 26). The horizontal white line in the violin plot represents the median. The grey dots represent the individual-level average natural logarithm of the EMG amplitude by muscle and condition."}
# position for groups
pd <- position_dodge(0.8)

# plotting the data
df2 %>%
    # reshapes data from wide to long format
    pivot_longer(
        cols = FRO:OOI,
        names_to = "muscle",
        values_to = "value",
        values_drop_na = TRUE
        ) %>%
    mutate(order = factor(order) ) %>%
    # plots the data
    ggplot(aes(x = condition, y = value) ) +
    # violin plots
    geom_violin(
        scale = "count",
        fill = "black",
        alpha = 0.15,
        colour = "white",
        position = pd,
        # adjust = 0.8,
        draw_quantiles = 0.5,
        show.legend = FALSE
        ) +
    # plotting individual data points
    geom_quasirandom(alpha = 0.3) +
    # plotting means
    stat_summary(
        fun = mean,
        geom = "line", size = 1,
        # aes(group = interaction(muscle, order) ),
        aes(group = muscle),
        position = pd,
        show.legend = FALSE
        ) +
    # plotting means
    stat_summary(
        fun = "mean",
        geom = "point", shape = 16, size = 3,
        position = pd,
        show.legend = TRUE
        ) +
    # plotting confidence intervals
    stat_summary(
        fun.data = mean_cl_normal,
        geom = "errorbar", size = 1, width = 0,
        fun.args = list(mult = 1.96),
        show.legend = FALSE,
        position = pd
        ) +
    # facetting by muscle
    facet_wrap(~muscle, ncol = 3) +
    # axis labels
    labs(x = "Condition", y = "Natural logarithm of peak amplitude") +
    theme_bw(base_size = 10) +
    scale_colour_brewer(palette = "Dark2", direction = 1) +
    scale_fill_brewer(palette = "Dark2", direction = 1)
```

To model EMG peak amplitude variations in response to the rumination and distraction inductions, we fitted a Bayesian multivariate regression model with the natural logarithm of the EMG peak amplitude as an outcome and *Condition* (baseline, rumination, distraction) as a categorical predictor. Therefore, the intercept represents the estimated logarithm of the EMG peak amplitude in the `baseline` condition, and the slopes for the `rumination` and `distraction` conditions represent deviations from the baseline. These analyses were conducted using the `brms` package [@R-brms], an `R` implementation of Bayesian multilevel models that employs the probabilistic programming language `Stan` [@carpenter_stan_2017]. We ran four chains including each 10.000 iterations and a warmup of 2.000 iterations. Posterior convergence was assessed examining autocorrelation and trace plots, as well as the Gelman-Rubin statistic. Constant effects estimates were summarised via their posterior mean and 95% credible interval. We also report Bayes factors (BFs) computed using the Savage-Dickey method.^[This method simply consists in taking the ratio of the posterior density at the point of interest divided by the prior density at that point [@wagenmakers_bayesian_2010].] These BFs can be interpreted as updating factors, from prior knowledge (what we knew before seeing the data) to posterior knowledge (what we know after seeing the data). A summary of the estimations from this model is presented in Table \@ref(tab:summary). This analysis revealed that...

```{r models, results = "hide"}
##############################
# Bayesian multilevel models #
##############################

# priors for the constant-effects model
priors_constant <- c(
    prior(normal(0, 5), class = b, coef = Intercept, resp = "FRO"),
    prior(normal(0, 1), class = b, resp = "FRO"),
    prior(exponential(1), class = sigma, resp = "FRO"),
    prior(normal(0, 5), class = b, coef = Intercept, resp = "OOS"),
    prior(normal(0, 1), class = b, resp = "OOS"),
    prior(exponential(1), class = sigma, resp = "OOS"),
    prior(normal(0, 5), class = b, coef = Intercept, resp = "OOI"),
    prior(normal(0, 1), class = b, resp = "OOI"),
    prior(exponential(1), class = sigma, resp = "OOI")
    )

# fitting the model
constant_effects <- brm(
    mvbind(FRO, OOS, OOI) ~ 0 + Intercept + condition,
    family = gaussian(),
    prior = priors_constant,
    data = df2,
    chains = 4, cores = detectCores(),
    warmup = 2000, iter = 10000,
    control = list(adapt_delta = 0.95),
    sample_prior = TRUE,
    file = here("models/constant_effects")
    )

# priors for the varying-effects model
# priors_varying <- c(
#     prior(normal(0, 10), class = Intercept, resp = "FRO"),
#     prior(normal(0, 1), class = b, resp = "FRO"),
#     prior(exponential(1), class = sigma, resp = "FRO"),
#     prior(exponential(1), class = sd, resp = "FRO"),
#     prior(normal(0, 10), class = Intercept, resp = "OOS"),
#     prior(normal(0, 1), class = b, resp = "OOS"),
#     prior(exponential(1), class = sigma, resp = "OOS"),
#     prior(exponential(1), class = sd, resp = "OOS"),
#     prior(normal(0, 10), class = Intercept, resp = "OOI"),
#     prior(normal(0, 1), class = b, resp = "OOI"),
#     prior(exponential(1), class = sigma, resp = "OOI"),
#     prior(exponential(1), class = sd, resp = "OOI")
#     )

# fitting the model
# varying_effects <- brm(
#     mvbind(FRO, OOS, OOI) ~ 1 + condition + (1 | ID),
#     family = gaussian(),
#     prior = priors_varying,
#     data = df2,
#     chains = 4, cores = detectCores(),
#     warmup = 2000, iter = 10000,
#     control = list(adapt_delta = 0.95),
#     sample_prior = TRUE,
#     file = here("models/varying_effects")
#     )

# priors for the varying-effects model
priors_varying <- c(
    prior(normal(0, 5), class = b, coef = Intercept, resp = "FRO"),
    prior(normal(0, 1), class = b, resp = "FRO"),
    prior(exponential(1), class = sigma, resp = "FRO"),
    prior(exponential(1), class = sd, resp = "FRO"),
    prior(normal(0, 5), class = b, coef = Intercept, resp = "OOS"),
    prior(normal(0, 1), class = b, resp = "OOS"),
    prior(exponential(1), class = sigma, resp = "OOS"),
    prior(exponential(1), class = sd, resp = "OOS"),
    prior(normal(0, 5), class = b, coef = Intercept, resp = "OOI"),
    prior(normal(0, 1), class = b, resp = "OOI"),
    prior(exponential(1), class = sigma, resp = "OOI"),
    prior(exponential(1), class = sd, resp = "OOI")
    )

# fitting the model (for computing the bf on the intercept)
varying_effects <- brm(
    mvbind(FRO, OOS, OOI) ~ 0 + Intercept + condition + (0 + Intercept | ID),
    family = gaussian(),
    prior = priors_varying,
    data = df2,
    chains = 4, cores = detectCores(),
    warmup = 2000, iter = 10000,
    control = list(adapt_delta = 0.95),
    sample_prior = TRUE,
    file = here("models/varying_effects")
    )
```

```{r bf, eval = FALSE, fig.width = 10, fig.cap = "Savage-Dickey Bayes factor for the difference between the rumination and distraction conditions for each muscle. The BF is computed as the ratio of the posterior density to the prior density at $\\theta = 0$."}
# BF testing
hyp_fro <- hypothesis(
    varying_effects,
    "FRO_conditionDIS = FRO_conditionRUM"
    )

p1 <- plot(hyp_fro, plot = FALSE, theme = theme_bw(base_size = 12) )[[1]] +
    geom_vline(xintercept = 0, linetype = 2) +
    coord_cartesian(xlim = c(-5, 5) ) +
    theme_bw(base_size = 10) +
    theme(legend.title = element_blank() ) +
    labs(
      x = "Log EMG peak amplitude",
      title = paste0(
        "BF10 = ", round(1 / hyp_fro$hypothesis$Evid.Ratio, 3),
        " (BF01 = ", round(hyp_fro$hypothesis$Evid.Ratio, 3), ")"
        )
      )

hyp_ooi <- hypothesis(
    varying_effects,
    "OOI_conditionDIS = OOI_conditionRUM"
    )

p2 <- plot(hyp_ooi, plot = FALSE, theme = theme_bw(base_size = 12) )[[1]] +
    geom_vline(xintercept = 0, linetype = 2) +
    coord_cartesian(xlim = c(-5, 5) ) +
    theme_bw(base_size = 10) +
    theme(legend.title = element_blank() ) +
    labs(
      x = "Log EMG peak amplitude",
      title = paste0(
        "BF10 = ", round(1 / hyp_ooi$hypothesis$Evid.Ratio, 3),
        " (BF01 = ", round(hyp_ooi$hypothesis$Evid.Ratio, 3), ")"
        )
      )

hyp_oos <- hypothesis(
    varying_effects,
    "OOS_conditionDIS = OOS_conditionRUM"
    )

p3 <- plot(hyp_oos, plot = FALSE, theme = theme_bw(base_size = 12) )[[1]] +
    geom_vline(xintercept = 0, linetype = 2) +
    coord_cartesian(xlim = c(-5, 5) ) +
    theme_bw(base_size = 10) +
    theme(legend.title = element_blank() ) +
    labs(
      x = "Log EMG peak amplitude",
      title = paste0(
        "BF10 = ", round(1 / hyp_oos$hypothesis$Evid.Ratio, 3),
        " (BF01 = ", round(hyp_oos$hypothesis$Evid.Ratio, 3), ")"
        )
      )

p1 + p2 + p3 + plot_layout(guides = "collect") & theme(legend.position = "bottom")
```

```{r summary, result = "asis"}
changeSciNot <- function(n) {
  
  output <- format(n, digits = 4, scientific = TRUE)
  output <- sub("e", "*10^", output)
  output <- sub("\\+0?", "", output)
  output <- sub("-0?", "-", output)
  output
  
}

summary_varying_effects <-
    # retrieve estimations from bmod5
    summary(varying_effects, prob = 0.95)$fixed %>%
    # convert to dataframe
    data.frame %>%
    # sets rownames as the first column
    rownames_to_column(var = "response") %>%
    # removing ESS information
    dplyr::select(-Bulk_ESS, -Tail_ESS) %>%
    # split response name as two columns
    # separate(col = response, into = c("response", "term"), sep = "_", extra = "merge") %>%
    # rename columns
    magrittr::set_colnames(
        c("Term", "Estimate", "SE", "Lower", "Upper", "Rhat")
        ) %>%
    # compute BF for each effect
    mutate(
        BF10 = 1 / hypothesis(
          varying_effects, glue("{Term} = 0")
          )$hypothesis$Evid.Ratio
        ) %>%
    # round BFs
    # mutate(BF01 = ifelse(BF01 < .001, "<0.001", BF01) ) %>%
    mutate(
      BF10 = ifelse(
        BF10 < 0.001 | BF10 > 1e3,
        changeSciNot(abs(BF10) ),
        round(BF10, 3)
        )
      ) %>%
    # if numeric, round to 3 decimals
    mutate_if(is.numeric, round, 3)

apa_table(
    summary_varying_effects,
    placement = "H",
    digits = 3,
    align = c("l", rep("c", 6) ),
    caption = "Estimated value of the natural logarithm of the EMG peak amplitude in each condition and for each muscle.",
    note = "For each effect, the 'Estimate' reports the estimated average value of the natural logarithm of the EMG peak amplitude, followed by its standard error (SE). The 'Lower' and 'Upper' columns contain the lower and upper bounds of the 95% CrI, whereas the 'Rhat' column reports the Gelman-Rubin statistic. The last column reports the BF in favour of the alternative hypothesis (relative to the null hypothesis).",
    small = TRUE,
    escape = TRUE
    )
```

Because the results of such an analysis is a joint posterior probability over all parameters of the model, we can compute the posterior distribution of the difference between the conditions of interest (i.e., the difference between the rumination and the distraction conditions). Thus, in Figure \@ref(fig:posterior) we represent the posterior distribution of the difference in EMG peak amplitude between the rumination and distraction condition for each muscle...

```{r posterior, fig.width = 10, fig.height = 5, eval = TRUE, fig.cap = "Posterior distribution of the difference in EMG peak amplitude between the rumination and distraction condition for each muscle, along with its mean and 95\\% credible interval."}
# extracts posterior samples
post <- posterior_samples(varying_effects)

# grid of plots
par(mfrow = c(1, 3) )

plotPost(
    post$b_FRO_conditionRUM - post$b_FRO_conditionDIS,
    compVal = 0, xlab = "Rumination - Distraction", main = "FRO"
    )

plotPost(
    post$b_OOI_conditionRUM - post$b_OOI_conditionDIS,
    compVal = 0, xlab = "Rumination - Distraction", main = "OOI"
    )

plotPost(
    post$b_OOS_conditionRUM - post$b_OOS_conditionDIS,
    compVal = 0, xlab = "Rumination - Distraction", main = "OOS"
    )
```

We now turn to a discussion of the problems related to conclusions that can be made from a low-powered non-significant result...

## Concluding on the null from under-powered studies: what could go wrong?

There is an infamous tradition of running uninformative null-hypothesis significance tests in Psychology [e.g., @harlow_problem_1997; @meehl_appraising_1990-1; @meehl_theoretical_1978; @meehl_theory-testing_1967; @meehl_why_1990]. By "uninformative", we mean that some null-hypothesis significance tests are *not* diagnostic with regards to the substantive effect of interest (e.g., whether there is a difference between conditions A and B).

As highlighted by many authors [e.g., @pollard_probability_1987; @rouder_is_2016], concluding that an effect is probably based on a non-significant *p*-value is the continuous (i.e., probabilistic) extension of the logical fallacy of the ... This fallacious argument is also known as the *fallacy of acceptance*, the *absence of evidence fallacy* or *the argument from ignorance*, which proceeds as follows: "Science has found no proof of intelligent life nearby us in space, therefore intelligent life does not exist nearby us in space." This argument is fallacious in that it considers that not finding evidence for a claim is evidence for the contrapositive.

This problem is tackled in modern usages of null-hypothesis significance test by ensuring that the claim under scrutiny is submitted to *severe* tests [e.g., @mayo_severe_2006; @mayo_statistical_2018]. In general terms, we have evidence for a claim to the extent that it survives a stringent scrutiny, that is, to the extent that it survives *severe* tests. More precisely, some claim (e.g., $\theta = 0$) is said to be *severely tested* if it had great chances of being falsified, was the claim false. More formally, we can define $\text{SEV}(T, x0, H)$, the severity with which claim $H$ passes test $T$ with outcome $x0$, and $\text{SEV}(\mu > \mu_{1}) = \Pr(d(X) \leq d(x0); \mu = \mu_{1})$ the... [@mayo_severe_2006; @mayo_statistical_2018]. To put it simply... https://www.analytics-toolkit.com/glossary/severity/...

When a statistical test is under-powered (for detecting a given effect size) the claim under scrutiny is not strongly (severely) tested, hence it not possible to obtain strong evidence (bad test, no evidence)...

Anticipating the legitimate critiques on the power of their study, @moffatt_inner_2020 report the results of a (possibly ran a posteriori) power analysis using the effect size reported in @nalborczyk_orofacial_2017 of $d = 0.72$. This represents a highly optimistic estimate of the substantive effect of interest (i.e., the difference in the natural logarithm of the EMG peak amplitude between the rumination and distraction conditions) as this effect represents the standardised mean difference in EMG amplitude *between a rest and a rumination periods* [@nalborczyk_orofacial_2017].

```{r power, echo = FALSE}
# How many participants do we need for a target statistical power of 0.8?
library(pwr)
pwr.t.test(
  d = 0.72, sig.level = 0.05, power = 0.8,
  type = "one.sample", alternative = "two.sided"
  )
```

We suggest the (a priori) power of the study ran by @moffatt_inner_2020 was much lower than suggested by the authors. Indeed, we may speculate that the standardised mean difference in EMG peak amplitude between the rumination and distraction conditions may be much weaker than the standardised mean difference in EMG amplitude between the rumination and rest conditions. If we assume that the former is half the size of the latter [which seems reasonable given the high inter-individual variability in such effects, cf. the next section but also @nalborczyk_can_2020], therefore the a priori power of the main statistical test from @moffatt_inner_2020 was around $0.44$, meaning that they had less than 1 chance out of 2 to find a significant effect (given that the effect in the population was actually $0.36$). Because this is less than the chance of obtaining a head in a coin flip, we feel these resources may have been better invested.

```{r actual_power, echo = TRUE}
# A priori power for n = 26 and d = 0.36
library(pwr)
pwr.t.test(
  n = 26, d = 0.72 / 2, sig.level = 0.05,
  type = "one.sample", alternative = "two.sided"
  )
```

Once again, anticipating the legitimate critique that the absence of a significant difference is not *necessarily* "significant" evidence for the absence of an effect, @moffatt_inner_2020 reported the following Bayes factor (BF) analysis:

> "[...] therefore it is possible that the sample size of the present study lacked sufficient power to detect the effect of rumination on muscle activity. In order to test this, a Bayesian paired samples t-test was conducted for the peak log values of muscle activity between the rumination and distraction conditions. This revealed strong evidence in favour of the alternative hypothesis for the FRO muscle ($B_{10} = 18.79$), and moderate evidence in favour of the null hypothesis for the OOS ($B_{10} = 0.232$) and OOI ($B_{10} = 0.278$) muscles, according to current guidelines for interpreting Bayes factors [43]."

<!--

While we appreciate the effort, the current approach poses new problems. First, contrary to what the authors suggest, computing a BF (i.e., comparing two models) does not solve *at all* the problem of low power (we discuss this issue in more depth below). Second, few details are given with regards to the exact models that were compared. Third, and most importantly, the BFs indicate moderate evidence in favour of the null for the OOI and OOS muscles. More precisely, these BFs indicated that the (observed) data are $1 / 0.232 \approx 4.31$ times more likely under the null than under the alternative hypothesis for the OOS and $1 / 0.278 \approx 3.6$ times more likely under the null than under the alternative hypothesis for the OOI. In other words, the evidence is favour of the null is relatively weak and sensitivity analyses (i.e., reporting the BF with varying prior scales for the alternative hypothesis) may unsurprisingly results in various BFs. For instance... 

-->

While we appreciate the effort, the current approach poses new problems. First, contrary to what the authors suggest, whereas computing a BF indeed allows assessing the *relative evidence* for the null, computing a BF (i.e., comparing two models) does not solve *at all* the problem of low power. More precisely, the sensitivity of an experiment design to detect a given effect is an issue that...

In the previous section, we fitted a multivariate Bayesian regression model with varying-intercepts by participant and weakly informative priors on the EMG data collected by @moffatt_inner_2020. Using this model, we i) generated new datasets from the posterior predictive distribution of this model and ii) we computed the BF in favour of the alternative hypothesis ($\text{BF}_{10}$) using the `BayesFactor` package [@R-BayesFactor]. We used a "medium" prior (i.e., a scale of 1) on the scale of the Cauchy prior for the alternative hypothesis. We repeated this procedure for varying sample sizes from 20 to 200 participants (by increments of 10 participants) with $1000$ simulations (i.e., 1000 simulated datasets) for each sample size.

```{r simulated-power, fig.cap = "Average natural logarithm of the Bayes factor in favour of the alternative hypothesis, along with its standard error, computed over 1000 datasets of increasing size simulated from the posterior predictive distribution of the varying-intercept multivariate Bayesian regresion model, fitted on the data from Moffatt et al. (2020). A log-BF belows 0 represents evidence for the null hypothesis (relative to the alternative hypothesis) and a log-BF above 0 represents evidence for the alternative hypothesis (relative to the null hypothesis)."}
# running the simulations
# source("code/bf_simulation.R")

# loading the results
load(file = "results/overall_results.Rda")

# simulations parameters
nsims <- 1e3
sample_size <- seq.int(from = 20, to = 200, by = 10)

# plotting the results
overall_results %>%
    na.omit() %>%
    filter_all(any_vars(. != 0) ) %>%
    pivot_longer(cols = bf_fro:bf_oos, names_to = "bf_type") %>%
    mutate(value = log(value) ) %>%
    mutate(bf_type = factor(bf_type, labels = c("FRO", "OOI", "OOS") ) ) %>%
    group_by(nobs, bf_type) %>%
    summarise(
        across(
            .cols = value,
            .fns = list(mean = mean, se = ~sd(.x) / sqrt(nsims) )
            )
        ) %>%
    ungroup() %>% 
    ggplot(aes(x = nobs, y = value_mean, colour = bf_type, fill = bf_type) ) +
    geom_hline(yintercept = 0, lty = 3) +
    geom_ribbon(
        aes(
          x = nobs, ymin = value_mean - 1.96 * value_se,
          ymax = value_mean + 1.96 * value_se, colour = NULL
          ),
        alpha = 0.5, show.legend = FALSE
        ) + 
    geom_line(show.legend = FALSE) +
    geom_point(show.legend = FALSE) +
    facet_wrap(~bf_type, scales = "free") +
    scale_x_continuous(breaks = unique(sample_size)[c(TRUE, FALSE)]) +
    theme_bw(base_size = 10) +
    labs(x = "Number of participants", y = "Natural logarithm of the Bayes factor") +
    scale_colour_brewer(palette = "Dark2", direction = 1) +
    scale_fill_brewer(palette = "Dark2", direction = 1)
```

As shown in Figure \@ref(fig:simulated-power), the natural logarithm of the BF in favour of the alternative hypothesis is growing proportionally with sample size. More precisely, whereas BFs computed on small samples (i.e., below 80 participants) support the null hypothesis, BFs computed on adequately-powered samples support the alternative hypothesis for all three facial muscles. For instance, the average $\text{BF}_{10}$ computed for the OOI muscle with a sample size of 160 participants is of $\exp(2.18) \approx 8.85$, indicating that these data are approximately $8.85$ times more likely under the alternative hypothesis than under the null hypothesis. To sum up, this reveals that although at low sample sizes, the BF may provide (weak) evidence for the null hypothesis (relative to the alternative hypothesis) this pattern may very well reverse for higher sample sizes.

We should keep in mind some limitations of this analysis, which uses simulated datasets form the posterior predictive distribution estimated on the data collected by @moffatt_inner_2020. This analysis is the loose Bayesian analogue of the frequentist post-hoc power analysis, which has been much criticised [e.g., @lakens_20_2014]. A crucial assumption of the present analysis is that the data from @moffatt_inner_2020 is our best source of information regarding the main effect of interest. However, the present analysis also differs from the frequentist post-hoc power analysis on several grounds. First, with the present analysis, we do not aim to assess the ability of our statistical test to pass some dichotomic threshold (e.g., accept/reject). Instead, we aim to assess how the $\text{BF}_{10}$ (i.e., the evidence for the alternative hypothesis, relative to the null hypothesis) behaves with varying sample sizes. Second, the present analysis relies on the posterior predictive distribution of the model fitted on the data from @moffatt_inner_2020, which naturally incorporates uncertainty about the effect of interest. By simulating datasets of varying sample sizes from the posterior predictive distribution (and by relying on a large number of simulations), uncertainty about the effect size is naturally incorporated into the simulation.

## Within-subject manipulation of rumination and distraction

In @nalborczyk_dissociating_2020, we manipulated the modality of rumination (whether it is verbal or non-verbal) in a between-subject manner to avoid order effects... In contrast to this approach, @moffatt_inner_2020 asked participants to ruminate and then distract themselves (or reciprocally), after an induced stressor (an induced failure)...

```{r order, fig.cap = "Average log-EMG amplitude by muscle and condition. The black dots and intervals represent the by-group average and 95\\% confidence interval (N = 26). The horizontal white line in the violin plot represents the median. The grey dots represent the individual-level average natural logarithm of the EMG amplitude by muscle and condition."}
# position for groups
pd <- position_dodge(0.8)

# plotting the data
df2 %>%
    # reshapes data from wide to long format
    pivot_longer(
        cols = FRO:OOI,
        names_to = "muscle",
        values_to = "value",
        values_drop_na = TRUE
        ) %>%
    mutate(order = factor(order, labels = c("RUM -> DIS", "DIS -> RUM")) ) %>%
    # plots the data
    ggplot(aes(x = condition, y = value, colour = order, fill = order) ) +
    # plotting individual data points
    geom_quasirandom(alpha = 0.3) +
    # plotting means
    stat_summary(
        fun.y = mean,
        geom = "line", size = 1,
        aes(group = interaction(muscle, order) ),
        # aes(group = muscle),
        position = pd,
        show.legend = FALSE
        ) +
    # plotting means
    stat_summary(
        fun.y = "mean",
        geom = "point", shape = 16, size = 3,
        position = pd,
        show.legend = TRUE
        ) +
    # plotting confidence intervals
    stat_summary(
        fun.data = mean_cl_normal,
        geom = "errorbar", size = 1, width = 0,
        fun.args = list(mult = 1.96),
        show.legend = FALSE,
        position = pd
        ) +
    # facetting by muscle
    facet_wrap(~muscle, ncol = 3) +
    labs(x = "Condition", y = "Natural logarithm of peak amplitude") +
    theme_bw(base_size = 10) +
    scale_colour_brewer(palette = "Dark2", direction = 1) +
    scale_fill_brewer(palette = "Dark2", direction = 1) +
    theme(
      legend.title = element_blank(),
      # legend.position = c(0.85, 0.85),
      legend.position = "top",
      legend.background = element_rect(size = 0.5, linetype = "solid", colour = "black")
    )
```

About the order effects, @moffatt_inner_2020 say:

> "Unless otherwise reported, the inclusion of order in which the conditions were completed as a between-subjects variable as part of a mixed-design ANOVA produced no significant main effects or interactions involving order."

Unfortunately, the same line of reasoning applies for testing the effect of the order, which is even less powered than the test of the main effect of interest, rendering it practically uninformative...

## Does everyone show the effect?

...

```{r everyone, fig.cap = "Inter-individual variability in the main effect of interest (i.e., the difference between the rumination and distraction conditions). Green dots and lines represent the average natural logarithm of the EMG amplitude of participants that showed a higher EMG amplitude in the rumination condition than in the distraction condition, whereas orange dots and lines represent the average natural logarithm of the EMG amplitude of participants that showed a higher EMG amplitude in the distraction condition than in the rumination condition."}
# does everyone plot
df2 %>%
    pivot_longer(cols = FRO:OOI, names_to = "muscle") %>%
    pivot_wider(names_from = condition, values_from = value) %>%
    mutate(ruminator = ifelse(RUM > DIS, 1, 0) ) %>%
    mutate(ruminator = as.factor(ruminator) ) %>%
    mutate(rum_dis = RUM - DIS) %>%
    pivot_longer(cols = RUM:BAS, names_to = "condition") %>%
    ggplot(aes(x = condition, y = value, colour = ruminator) ) +
    # violin plots
    geom_violin(
        scale = "count",
        fill = "black",
        alpha = 0.15,
        colour = "white",
        position = pd,
        # adjust = 0.8,
        draw_quantiles = 0.5,
        show.legend = FALSE
        ) +
    # plotting individual data points
    geom_point(size = 2, alpha = 0.8, show.legend = FALSE) +
    # plotting individual trajectories
    geom_line(aes(group = ID), size = 0.5, alpha = 0.8, show.legend = FALSE) +
    # facetting by muscle
    facet_wrap(~muscle) +
    # axis labels
    labs(x = "Condition", y = "Natural logarithm of peak amplitude") +
    theme_bw(base_size = 10) +
    # scale_color_gradient2(midpoint = 0, low = "red", mid = "green", high = "blue", space = "Lab")
    scale_colour_brewer(palette = "Dark2", direction = -1) +
    scale_fill_brewer(palette = "Dark2", direction = -1)
```

Huge inter-individual variability... It should be noted that the question of the qualitative differences in the EMG correlates of inner speech may be assessed formally via the model comparison approach developped by @haaf_developing_2017. However, this would require data coming from an experimental design in which inner speech and non-inner speech conditions would be manipulated within-subject and with multiple observations for each participants in each condition [such as in @nalborczyk_can_2020], so that multilevel models with both varying intercepts and varying slopes could be estimated.

<!--

Which leads to the next point, what is the relation between self-reports and EMG?

## Relating the subjective inner experience to the psychophysiological correlates

From page 10: "Independent t-tests revealed that inner speech in the rumination condition was rated as more Condensed if it was engaged in first, compared to if it was completed second (t(29) = 3.237, p = 0.003, d = 1.163). The rumination condition was rated as involving more Positive inner speech by those who engaged in rumination first, compared to those who completed rumina- tion second (t(29) = 2.513, p = 0.018, d = 0.903). In summary, rumination tended to involve more Condensed and Positive inner speech if engaged in first"...

```{r reports, eval = FALSE}
# reshaping from wide to long
EMG <- df %>%
    select(ID, order = Order, RUM_FRO_MAX_ln:BAS_OOI_MAX_ln) %>%
    na.omit %>%
    # reshapes data from wide to long format
    pivot_longer(
        cols = starts_with(c("RUM", "DIS", "BAS") ),
        names_to = "condition",
        # names_prefix = "wk",
        values_to = "EMG",
        values_drop_na = TRUE
        ) %>%
    separate(
        col = condition,
        into = c("condition", "muscle"),
        sep = "_", extra = "merge"
        ) %>%
    # extracts muscle name
    mutate(muscle = substr(muscle, 1, 3) )

ESM <- df %>%
    select(ID, order = Order, DIS_Future:RUM_Thoughts) %>%
    na.omit %>%
    # reshapes data from wide to long format
    pivot_longer(
        cols = starts_with(c("RUM", "DIS") ),
        names_to = "condition",
        # names_prefix = "wk",
        values_to = "ESM",
        values_drop_na = TRUE
        ) %>%
    separate(
        col = condition,
        into = c("condition", "esm_scale"),
        sep = "_", extra = "merge"
        )

VISQ <- df %>%
    select(ID, order = Order, starts_with("VISQ") ) %>%
    na.omit %>%
    # reshapes data from wide to long format
    pivot_longer(
        cols = starts_with("VISQ"),
        names_to = "visq_item",
        # names_prefix = "wk",
        values_to = "visq_value",
        values_drop_na = TRUE
        ) %>%
    separate(
        col = visq_item,
        into = c("visq_item", "condition"),
        sep = "_(?=[^_]+$)"
        # sep = "_", extra = "merge"
        )

# MOOD <- df %>%
#     select(ID, order = Order, PANAS_T1:VAS_Sad_T2) %>%
#     na.omit

VAS <- df %>%
    select(ID, order = Order, VAS_Feelings_RUM:VAS_Problems_DIS) %>%
    na.omit %>%
    # reshapes data from wide to long format
    pivot_longer(
        cols = starts_with("VAS"),
        names_to = "vas_item",
        # names_prefix = "wk",
        values_to = "vas_value",
        values_drop_na = TRUE
        ) %>%
    separate(
        col = vas_item,
        into = c("vas_item", "condition"),
        sep = "_(?=[^_]+$)"
        # sep = "_", extra = "merge"
        )

df3 <- bind_cols(c(EMG, ESM, VAS, VISQ) )
```

-->

# Discussion and conclusions

Summary of the methodological arguments + theoretical discussion from @nalborczyk_understanding_2019...

"Given that lip muscle activity has previously been related to inner speech production [23], this suggests that rumination has no specific boost of inner speech production relative to distraction. The increase in lip-muscle activity during states where thoughts were guided (rumination, distraction), compared to rest may therefore reflect the extra effort required to guide one’s thoughts and to engage in inner speech production"...

"In conclusion, induced rumination appeared to involve similar levels of inner speech- related muscle activity to a period of distraction"...

# Supplementary materials {#supp}

Reproducible code and figures are available at https://github.com/lnalborczyk/inner_experience_EMG.

# Acknowledgements {-}

Acknowledgements will be included in the final version of this manuscript.

# References {-}

```{r create_r_references, cache = FALSE}
r_refs(file = "bib/r-references.bib")
```
