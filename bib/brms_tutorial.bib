
@book{gelman_data_2006,
	address = {Leiden},
	title = {Data {Analysis} {Using} {Regression} and {Multilevel}/{Hierarchical} {Models}.},
	isbn = {978-0-511-26878-6},
	abstract = {For the applied researcher performing data analysis using linear and nonlinear regression and multilevel models.},
	language = {English},
	publisher = {Cambridge University Press},
	author = {Gelman, Andrew and Hill, Jennifer},
	year = {2006},
	note = {OCLC: 437176913},
	file = {Gelman & Hill - 2006.pdf:/Users/Ladislas/Zotero/storage/8GVJVHUG/Gelman & Hill - 2006.pdf:application/pdf;Gelman & Hill - 2006.pdf:/Users/Ladislas/Zotero/storage/AJAK443M/Gelman & Hill - 2006.pdf:application/pdf}
}

@article{gelman_philosophy_2013,
	title = {Philosophy and the practice of {Bayesian} statistics: {Philosophy} and the practice of {Bayesian} statistics},
	volume = {66},
	issn = {00071102},
	shorttitle = {Philosophy and the practice of {Bayesian} statistics},
	url = {http://doi.wiley.com/10.1111/j.2044-8317.2011.02037.x},
	doi = {10.1111/j.2044-8317.2011.02037.x},
	language = {en},
	number = {1},
	urldate = {2018-03-29},
	journal = {British Journal of Mathematical and Statistical Psychology},
	author = {Gelman, Andrew and Shalizi, Cosma Rohilla},
	month = feb,
	year = {2013},
	pages = {8--38},
	file = {Gelman & Shalizi - 2013.pdf:/Users/Ladislas/Zotero/storage/JHC3CMYF/Gelman & Shalizi - 2013.pdf:application/pdf;Gelman & Shalizi - 2013.pdf:/Users/Ladislas/Zotero/storage/RB7M5MIH/Gelman & Shalizi - 2013.pdf:application/pdf}
}

@article{gelman_why_2012,
	title = {Why we (usually) don't have to worry about multiple comparisons},
	volume = {5},
	issn = {1934-5747, 1934-5739},
	url = {http://www.tandfonline.com/doi/abs/10.1080/19345747.2011.618213},
	doi = {10.1080/19345747.2011.618213},
	language = {en},
	number = {2},
	urldate = {2018-03-29},
	journal = {Journal of Research on Educational Effectiveness},
	author = {Gelman, Andrew and Hill, Jennifer and Yajima, Masanao},
	month = apr,
	year = {2012},
	pages = {189--211},
	file = {Gelman et al. - 2012 - Why We (Usually) Don't Have to Worry About Multipl.pdf:/Users/Ladislas/Zotero/storage/9B6WS2AV/Gelman et al. - 2012 - Why We (Usually) Don't Have to Worry About Multipl.pdf:application/pdf;Gelman et al. - 2012 - Why We (Usually) Don't Have to Worry About Multipl.pdf:/Users/Ladislas/Zotero/storage/XB3EC5X4/Gelman et al. - 2012 - Why We (Usually) Don't Have to Worry About Multipl.pdf:application/pdf;Gelman, Hill, & Yajima - 2012.pdf:/Users/Ladislas/Zotero/storage/ZLI6I99T/Gelman, Hill, & Yajima - 2012.pdf:application/pdf;Gelman, Hill, & Yajima - 2012.pdf:/Users/Ladislas/Zotero/storage/Y4BRYFM2/Gelman, Hill, & Yajima - 2012.pdf:application/pdf}
}

@book{gelman_bayesian_2013,
	title = {Bayesian data analysis, third edition},
	publisher = {CRC Press, Taylor \& Francis Group},
	author = {Gelman, Andrew and Carlin, John B. and Stern, Hal and Dunson, D. B. and Vehtari, Aki and Rubin, Donald B.},
	year = {2013},
	file = {Gelman, Carlin, Stern, Dunson, Vehtari,  & Rubin - 2014.pdf:/Users/Ladislas/Zotero/storage/JED56PKJ/Gelman, Carlin, Stern, Dunson, Vehtari,  & Rubin - 2014.pdf:application/pdf}
}

@article{nalborczyk_introduction_2019,
	title = {An introduction to {Bayesian} multilevel models using brms: {A} case study of gender effects on vowel variability in standard indonesian},
	volume = {62},
	doi = {10.1044/2018_JSLHR-S-18-0006},
	abstract = {Purpose: Bayesian multilevel models are increasingly used to overcome the limitations of frequentist approaches in the analysis of complex structured data. This paper introduces Bayesian multilevel modelling for the speciﬁc analysis of speech data, using the brms package developed in R. Method: In this tutorial, we provide a practical introduction to Bayesian multilevel modelling, by reanalysing a phonetic dataset containing formant (F1 and F2) values for ﬁve vowels of Standard Indonesian (ISO 639-3:ind), as spoken by eight speakers (four females), with several repetitions of each vowel. Results: We ﬁrst give an introductory overview of the Bayesian framework and multilevel modelling. We then show how Bayesian multilevel models can be ﬁtted using the probabilistic programming language Stan and the R package brms, which provides an intuitive formula syntax. Conclusions: Through this tutorial, we demonstrate some of the advantages of the Bayesian framework for statistical modelling and provide a detailed case study, with complete source code for full reproducibility of the analyses (https://osf.io/dpzcb/).},
	language = {en},
	number = {5},
	journal = {Journal of Speech Language and Hearing Research},
	author = {Nalborczyk, Ladislas and Batailler, Cédric and Lœvenbruck, Hélène and Vilain, Anne and Bürkner, Paul-Christian},
	year = {2019},
	pages = {1225--1242},
	file = {Nalborczyk et al. - An Introduction to Bayesian Multilevel Models Usin.pdf:/Users/Ladislas/Zotero/storage/QIN8YUJV/Nalborczyk et al. - An Introduction to Bayesian Multilevel Models Usin.pdf:application/pdf}
}

@article{burkner_advanced_2018,
	title = {Advanced {Bayesian} {Multilevel} {Modeling} with the {R} {Package} brms},
	volume = {10},
	issn = {2073-4859},
	url = {https://journal.r-project.org/archive/2018/RJ-2018-017/index.html},
	language = {en},
	number = {1},
	urldate = {2019-06-11},
	journal = {The R Journal},
	author = {Bürkner, Paul-Christian},
	year = {2018},
	pages = {395--411},
	file = {Snapshot:/Users/Ladislas/Zotero/storage/B4954K2B/index.html:text/html}
}

@book{mcelreath_statistical_2020,
	address = {Boca Raton},
	edition = {2},
	series = {{CRC} texts in statistical science},
	title = {Statistical rethinking: a {Bayesian} course with examples in {R} and {Stan}},
	isbn = {978-0-367-13991-9},
	shorttitle = {Statistical rethinking},
	abstract = {"Statistical Rethinking: A Bayesian Course with Examples in R and Stan, Second Edition builds knowledge/confidence in statistical modeling. Pushes readers to perform step-by-step calculations (usually automated.) Unique, computational approach ensures readers understand details to make reasonable choices and interpretations in their modeling work"--},
	publisher = {Taylor and Francis, CRC Press},
	author = {McElreath, Richard},
	year = {2020}
}

@book{mcelreath_statistical_2016,
	address = {Boca Raton},
	series = {Chapman \& {Hall}/{CRC} texts in statistical science series},
	title = {Statistical rethinking: a {Bayesian} course with examples in {R} and {Stan}},
	isbn = {978-1-4822-5344-3},
	shorttitle = {Statistical rethinking},
	number = {122},
	publisher = {CRC Press/Taylor \& Francis Group},
	author = {McElreath, Richard},
	year = {2016},
	keywords = {Bayesian statistical decision theory, R (Computer program language)},
	annote = {"A CRC title."}
}

@article{the_manybabies_consortium_quantifying_2020,
	title = {Quantifying {Sources} of {Variability} in {Infancy} {Research} {Using} the {Infant}-{Directed}-{Speech} {Preference}:},
	shorttitle = {Quantifying {Sources} of {Variability} in {Infancy} {Research} {Using} the {Infant}-{Directed}-{Speech} {Preference}},
	url = {https://journals.sagepub.com/doi/10.1177/2515245919900809},
	doi = {10.1177/2515245919900809},
	abstract = {Psychological scientists have become increasingly concerned with issues related to methodology and replicability, and infancy researchers in particular face spe...},
	language = {en},
	urldate = {2020-05-13},
	journal = {Advances in Methods and Practices in Psychological Science},
	author = {The ManyBabies Consortium},
	month = mar,
	year = {2020},
	note = {Publisher: SAGE PublicationsSage CA: Los Angeles, CA},
	file = {Consortium_2020_Quantifying Sources of Variability in Infancy Research Using the.pdf:/Users/Ladislas/Zotero/storage/BYSUH8EE/Consortium_2020_Quantifying Sources of Variability in Infancy Research Using the.pdf:application/pdf;Snapshot:/Users/Ladislas/Zotero/storage/29RJZTBN/2515245919900809.html:text/html}
}

@article{burkner_ordinal_2019,
	title = {Ordinal {Regression} {Models} in {Psychology}: {A} {Tutorial}:},
	shorttitle = {Ordinal {Regression} {Models} in {Psychology}},
	url = {https://journals.sagepub.com/doi/10.1177/2515245918823199},
	doi = {10.1177/2515245918823199},
	abstract = {Ordinal variables, although extremely common in psychology, are almost exclusively analyzed with statistical models that falsely assume them to be metric. This ...},
	language = {en},
	urldate = {2020-05-13},
	journal = {Advances in Methods and Practices in Psychological Science},
	author = {Bürkner, Paul-Christian and Vuorre, Matti},
	month = feb,
	year = {2019},
	note = {Publisher: SAGE PublicationsSage CA: Los Angeles, CA},
	file = {Snapshot:/Users/Ladislas/Zotero/storage/CG3UJRE7/2515245918823199.html:text/html}
}

@article{csibra_statistical_2016,
	title = {Statistical {Treatment} of {Looking}-{Time} {Data}},
	volume = {52},
	issn = {0012-1649},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4817233/},
	doi = {10.1037/dev0000083},
	abstract = {Looking times (LTs) are frequently measured in empirical research on infant cognition. We analyzed the statistical distribution of LTs across participants to develop recommendations for their treatment in infancy research. Our analyses focused on a common within-subject experimental design, in which longer looking to novel or unexpected stimuli is predicted. We analyzed data from 2 sources: an in-house set of LTs that included data from individual participants (47 experiments, 1,584 observations), and a representative set of published articles reporting group-level LT statistics (149 experiments from 33 articles). We established that LTs are log-normally distributed across participants, and therefore, should always be log-transformed before parametric statistical analyses. We estimated the typical size of significant effects in LT studies, which allowed us to make recommendations about setting sample sizes. We show how our estimate of the distribution of effect sizes of LT studies can be used to design experiments to be analyzed by Bayesian statistics, where the experimenter is required to determine in advance the predicted effect size rather than the sample size. We demonstrate the robustness of this method in both sets of LT experiments.},
	number = {4},
	urldate = {2020-05-13},
	journal = {Developmental Psychology},
	author = {Csibra, Gergely and Hernik, Mikołaj and Mascaro, Olivier and Tatone, Denis and Lengyel, Máté},
	month = apr,
	year = {2016},
	pmid = {26845505},
	pmcid = {PMC4817233},
	pages = {521--536},
	file = {Csibra et al_2016_Statistical Treatment of Looking-Time Data.pdf:/Users/Ladislas/Zotero/storage/8SD79GYP/Csibra et al_2016_Statistical Treatment of Looking-Time Data.pdf:application/pdf}
}

@article{haines_learning_2020,
	title = {Learning from the {Reliability} {Paradox}: {How} {Theoretically} {Informed} {Generative} {Models} {Can} {Advance} the {Social}, {Behavioral}, and {Brain} {Sciences}},
	shorttitle = {Learning from the {Reliability} {Paradox}},
	url = {https://osf.io/xr7y3},
	abstract = {Behavioral tasks (e.g., Stroop task) that produce replicable group-level effects (e.g., Stroop effect) often fail to reliably capture individual differences between participants (e.g., low test-retest reliability). This “reliability paradox” has led many researchers to conclude that most behavioral tasks cannot be used to develop and advance theories of individual differences. However, these conclusions are derived from statistical models that provide only superficial summary descriptions of behavioral data, thereby ignoring theoretically-relevant data-generating mechanisms that underly individual-level behavior. More generally, such descriptive methods lack the flexibility to test and develop increasingly complex theories of individual differences. To resolve this theory-description gap, we present generative modeling approaches, which involve using background knowledge to specify how behavior is generated at the individual level, and in turn how the distributions of individual-level mechanisms are characterized at the group level—all in a single joint model. Generative modeling shifts our focus away from estimating descriptive statistical “effects” toward estimating psychologically meaningful parameters, while simultaneously accounting for measurement error that would otherwise attenuate individual difference correlations. Using simulations and empirical data from the Implicit Association Test and Stroop, Flanker, Posner Cueing, and Delay Discounting tasks, we demonstrate how generative models yield (1) higher test-retest reliability estimates, and (2) more theoretically informative parameter estimates relative to traditional statistical approaches. Our results reclaim optimism regarding the utility of behavioral paradigms for testing and advancing theories of individual differences, and emphasize the importance of formally specifying and checking model assumptions to reduce theory-description gaps and facilitate principled theory development.},
	urldate = {2020-08-25},
	author = {Haines, Nathaniel and Kvam, Peter D. and Irving, Louis H. and Smith, Colin and Beauchaine, Theodore P. and Pitt, Mark A. and Ahn, Woo-Young and Turner, Brandon},
	month = aug,
	year = {2020},
	doi = {10.31234/osf.io/xr7y3}
}

@article{rouder_psychometrics_2019,
	title = {A psychometrics of individual differences in experimental tasks},
	volume = {26},
	issn = {1531-5320},
	url = {https://doi.org/10.3758/s13423-018-1558-y},
	doi = {10.3758/s13423-018-1558-y},
	abstract = {In modern individual-difference studies, researchers often correlate performance on various tasks to uncover common latent processes. Yet, in some sense, the results have been disappointing as correlations among tasks that seemingly have processes in common are often low. A pressing question then is whether these attenuated correlations reflect statistical considerations, such as a lack of individual variability on tasks, or substantive considerations, such as that inhibition in different tasks is not a unified concept. One problem in addressing this question is that researchers aggregate performance across trials to tally individual-by-task scores. It is tempting to think that aggregation is fine and that everything comes out in the wash. But as shown here, this aggregation may greatly attenuate measures of effect size and correlation. We propose an alternative analysis of task performance that is based on accounting for trial-by-trial variability along with the covariation of individuals’ performance across tasks. The implementation is through common hierarchical models, and this treatment rescues classical concepts of effect size, reliability, and correlation for studying individual differences with experimental tasks. Using recent data from Hedge et al. Behavioral Research Methods, 50(3), 1166–1186, 2018 we show that there is Bayes-factor support for a lack of correlation between the Stroop and flanker task. This support for a lack of correlation indicates a psychologically relevant result—Stroop and flanker inhibition are seemingly unrelated, contradicting unified concepts of inhibition.},
	language = {en},
	number = {2},
	urldate = {2020-08-25},
	journal = {Psychonomic Bulletin \& Review},
	author = {Rouder, Jeffrey N. and Haaf, Julia M.},
	month = apr,
	year = {2019},
	pages = {452--467},
	file = {Rouder_Haaf_2019_A psychometrics of individual differences in experimental tasks.pdf:/Users/Ladislas/Zotero/storage/QAX58CVG/Rouder_Haaf_2019_A psychometrics of individual differences in experimental tasks.pdf:application/pdf}
}
